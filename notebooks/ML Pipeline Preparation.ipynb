{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, classification_report\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../../DisasterResponse.db')\n",
    "df = pd.read_sql('messages', con=engine)\n",
    "X = df[['message']]\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenize the provided text by\n",
    "        * removing punctuation\n",
    "        * tokenizing into words\n",
    "        * removing stopwords\n",
    "        * lemmatizing, including conversion to lowercase\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # tokenize into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    tokens = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # lemmatize, including conversion to lowercase\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(tok).lower().strip() for tok in tokens]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A Test individual pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.message.iloc[:n_samples], Y.iloc[:n_samples], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(tokenizer=tokenize)\n",
    "%time X_train_vect  = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 ms\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "%time X_train_tfidf = tfidf.fit_transform(X_train_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Classifier (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(), n_jobs=16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultiOutputClassifier(RandomForestClassifier(), n_jobs=16)\n",
    "%time clf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%time X_test_vect  = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%time X_test_tfidf = tfidf.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.47 s\n"
     ]
    }
   ],
   "source": [
    "%time Y_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer(tokenizer=tokenize, max_df=0.5, max_features=1000)),\n",
    "    ('TFIDF', TfidfTransformer()),\n",
    "    ('MultiRandomForest', MultiOutputClassifier(RandomForestClassifier(), n_jobs=12))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.message.iloc[:n_samples], Y.iloc[:n_samples], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "multilabel_confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, Y_pred, target_names=Y_test.columns, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters.\n",
    "(Searching for optimal parameters for CountVectorizer and RandomForest simultaneously took too long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'countVectorizer__max_df': (0.25, 0.5, 0.75),\n",
    "        'countVectorizer__max_features': (500, 1000, 5000),\n",
    "        'MultiRandomForest__estimator__n_estimators': [50, 100, 200],\n",
    "        'MultiRandomForest__estimator__min_samples_split': [3, 4, 5],\n",
    "    }\n",
    "\n",
    "# Score by f1 score\n",
    "f1_weighted_score = make_scorer(f1_score, average='weighted', zero_division=0)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, scoring=f1_weighted_score, n_jobs=1, verbose=5, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.510, total= 3.9min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.495, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.504, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 12.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 16.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.494, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.482, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.510, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.495, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.506, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.497, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.486, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.510, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.507, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.498, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.486, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.509, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.506, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.496, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.498, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.489, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.508, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.495, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.511, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.495, total= 4.4min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.496, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.486, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.510, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.496, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.508, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.491, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.508, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.499, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.507, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.499, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.490, total= 5.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.510, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.508, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.497, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.487, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.511, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.495, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.507, total= 5.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.496, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.496, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=3, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.485, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.510, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.495, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.509, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.497, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.498, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.487, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.512, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.494, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.506, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.498, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.502, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.492, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.509, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.508, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.499, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.494, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.489, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.509, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.496, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.509, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.485, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.510, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.506, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.501, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.498, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.486, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.512, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.509, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.495, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.487, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.509, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.501, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.507, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.501, total= 5.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.497, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.486, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.511, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.496, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.508, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.500, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.487, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.510, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.497, total= 5.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.509, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.499, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=4, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.488, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.510, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.500, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.507, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.495, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.499, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.488, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.511, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.497, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.507, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.497, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.488, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.510, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.498, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.505, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.496, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.495, total= 4.1min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=50, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.489, total= 4.2min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.511, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.496, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.508, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.501, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.500, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.487, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.510, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.497, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.508, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.499, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.500, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.490, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.511, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.498, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.507, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.497, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.497, total= 4.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=100, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.492, total= 4.4min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.510, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.507, total= 4.9min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.498, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.497, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.487, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.509, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.498, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.509, total= 4.5min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.499, total= 4.6min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.496, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.490, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.511, total= 5.3min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.497, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.508, total= 4.8min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.500, total= 4.8min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.498, total= 4.7min\n",
      "[CV] MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  MultiRandomForest__estimator__min_samples_split=5, MultiRandomForest__estimator__n_estimators=200, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.489, total= 4.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 707.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11h 51min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('countVectorizer',\n",
       "                                        CountVectorizer(max_df=0.5,\n",
       "                                                        max_features=1000,\n",
       "                                                        tokenizer=<function tokenize at 0x000002288BF6D430>)),\n",
       "                                       ('TFIDF', TfidfTransformer()),\n",
       "                                       ('MultiRandomForest',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(),\n",
       "                                                              n_jobs=12))]),\n",
       "             n_jobs=1,\n",
       "             param_grid={'MultiRandomForest__estimator__min_samples_split': [3,\n",
       "                                                                             4,\n",
       "                                                                             5],\n",
       "                         'MultiRandomForest__estimator__n_estimators': [50, 100,\n",
       "                                                                        200],\n",
       "                         'countVectorizer__max_df': (0.25, 0.5, 0.75),\n",
       "                         'countVectorizer__max_features': (500, 1000, 5000)},\n",
       "             scoring=make_scorer(f1_score, average=weighted, zero_division=0),\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([118.39256537, 125.98731017, 126.05974543, 125.99281204,\n",
       "        125.35403657, 126.05767691, 126.36557055, 125.72985053,\n",
       "        126.15377951, 131.1169883 , 131.21624613, 133.0197022 ,\n",
       "        132.44889271, 136.58924639, 132.51555538, 131.07609379,\n",
       "        132.20216656, 133.17715418, 142.90154326, 145.35490394,\n",
       "        160.9822619 , 146.34479785, 144.52763486, 147.31619978,\n",
       "        144.32023895, 143.69905245, 147.71126854, 125.93358123,\n",
       "        125.88600457, 125.54132164, 125.95784736, 125.71651256,\n",
       "        125.42670035, 126.34057438, 125.06870341, 126.32540357,\n",
       "        131.13095748, 132.29757607, 131.9879905 , 131.47109687,\n",
       "        131.52917254, 132.7994287 , 130.93714499, 131.13412821,\n",
       "        132.95561182, 143.1496489 , 142.51382816, 145.85423803,\n",
       "        144.08951056, 145.18944931, 146.92610919, 143.49140823,\n",
       "        143.55804884, 145.7858485 , 125.23681772, 125.50565124,\n",
       "        126.04740977, 125.98699558, 125.4093523 , 125.44807136,\n",
       "        125.81736982, 125.98546553, 125.61835718, 132.96737063,\n",
       "        132.18557382, 144.03244138, 131.881549  , 132.88896012,\n",
       "        132.42746615, 131.72761679, 132.57251811, 135.37236261,\n",
       "        145.17646825, 155.30598319, 146.4172523 , 145.17320764,\n",
       "        144.72969615, 149.66807175, 162.44221556, 150.65424263,\n",
       "        149.80575514]),\n",
       " 'std_fit_time': array([ 7.65114558,  0.31582165,  0.45587504,  1.24480999,  1.05731678,\n",
       "         0.86044443,  1.02248001,  0.31921744,  0.0461905 ,  0.37531292,\n",
       "         0.25190377,  0.92235732,  0.07268083,  4.85389602,  0.54501486,\n",
       "         0.06284797,  0.38842726,  0.49870646,  0.2033335 ,  0.05175519,\n",
       "        13.718889  ,  0.45646095,  0.32444   ,  0.31849909,  0.2337054 ,\n",
       "         1.05206001,  2.01339829,  0.47966182,  0.46477258,  0.50959408,\n",
       "         0.9540236 ,  0.52757251,  0.80207586,  0.09629667,  1.02901316,\n",
       "         0.31577146,  0.18359506,  1.00631249,  0.28026831,  0.62174022,\n",
       "         0.67408526,  0.89098144,  0.27247381,  0.13976967,  0.57018292,\n",
       "         0.17434835,  0.02756107,  0.77408695,  0.41486609,  0.36270976,\n",
       "         0.25405037,  0.45092165,  0.98497927,  0.24340355,  0.94882476,\n",
       "         0.3394022 ,  0.6605134 ,  0.83106172,  0.0210371 ,  0.03960383,\n",
       "         0.44169462,  0.31413841,  0.24891257,  0.39056242,  0.98261142,\n",
       "        11.83093619,  0.08259451,  0.64343596,  0.71789432,  0.06517696,\n",
       "         0.89897442,  1.48301077,  0.80655754,  8.59408772,  1.00123811,\n",
       "         0.17986977,  1.21829855,  0.58218384, 15.5291723 ,  0.79998052,\n",
       "         0.33823514]),\n",
       " 'mean_score_time': array([121.76082921, 122.14413488, 122.08368134, 122.55967021,\n",
       "        121.83473146, 122.22133827, 121.96070528, 122.62435853,\n",
       "        121.15196514, 123.56958723, 124.39772439, 124.31777525,\n",
       "        124.17800677, 123.00821269, 124.60337901, 122.82928193,\n",
       "        123.95469749, 124.76212656, 129.57789361, 129.42485833,\n",
       "        128.47924209, 131.60497165, 129.47580743, 129.6110909 ,\n",
       "        129.82584357, 148.83231246, 129.86392164, 121.96174693,\n",
       "        121.71244788, 122.79937065, 121.93084776, 121.99676883,\n",
       "        121.78355277, 121.40842044, 122.37363577, 121.71995616,\n",
       "        124.25277364, 124.32837987, 136.73765576, 123.47512233,\n",
       "        124.49114704, 123.83833182, 124.50456035, 123.47821355,\n",
       "        125.2698586 , 129.16102183, 144.86152029, 129.48111737,\n",
       "        129.68778062, 129.4516288 , 130.48532915, 149.31789136,\n",
       "        130.58796442, 129.88746834, 122.0922395 , 122.29171741,\n",
       "        122.22302651, 121.93443918, 122.47129166, 122.29839861,\n",
       "        121.84760797, 122.17173696, 122.97453773, 124.19590414,\n",
       "        125.55177248, 125.26519334, 124.97787011, 124.37621295,\n",
       "        125.31120515, 125.82342386, 124.75020468, 127.00419331,\n",
       "        132.126899  , 132.59741688, 131.03442693, 130.57335436,\n",
       "        129.62947941, 133.03814232, 135.73872113, 137.02522302,\n",
       "        135.71450806]),\n",
       " 'std_score_time': array([ 0.50700521,  0.4699682 ,  0.45817232,  0.25135088,  0.52224147,\n",
       "         0.41132355,  0.49840164,  0.83565199,  0.59581804,  1.82055306,\n",
       "         0.87513137,  0.18980789,  0.80175173,  0.23044288,  0.28636217,\n",
       "         0.64290178,  0.67376888,  0.90656316,  1.75412953,  0.35140705,\n",
       "         0.4355278 ,  0.78669977,  0.50080156,  0.24326134,  0.35049057,\n",
       "        18.56135452,  0.38651562,  0.66991401,  0.29350138,  0.27307141,\n",
       "         0.90628183,  0.67990172,  0.21610677,  0.44254363,  0.15882611,\n",
       "         0.24332118,  1.14733088,  0.57488513, 12.34037673,  0.31474793,\n",
       "         0.62116313,  0.49197614,  1.15046489,  0.31196666,  0.26202416,\n",
       "         0.50133359, 16.37051916,  0.40779197,  1.16842532,  0.19494617,\n",
       "         0.10013938, 19.73048949,  0.04726827,  0.47002292,  0.47804248,\n",
       "         1.23272955,  0.40763092,  1.27377987,  0.70334899,  0.08948195,\n",
       "         0.70891249,  0.36112261,  1.72561252,  0.97386086,  0.93725145,\n",
       "         0.48324597,  0.6258105 ,  0.61316359,  1.02494383,  1.36638808,\n",
       "         0.62907922,  1.32585168,  0.42129588,  0.17891788,  0.10535622,\n",
       "         0.6685437 ,  0.99211931,  0.51534283,  1.34881902,  0.40898776,\n",
       "         2.40022302]),\n",
       " 'param_MultiRandomForest__estimator__min_samples_split': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_MultiRandomForest__estimator__n_estimators': masked_array(data=[50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_countVectorizer__max_df': masked_array(data=[0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_countVectorizer__max_features': masked_array(data=[500, 1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 3,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 4,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 50,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 100,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'MultiRandomForest__estimator__min_samples_split': 5,\n",
       "   'MultiRandomForest__estimator__n_estimators': 200,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000}],\n",
       " 'split0_test_score': array([0.5103567 , 0.50384417, 0.49430571, 0.50953708, 0.50641339,\n",
       "        0.49608105, 0.50961511, 0.50746849, 0.49606986, 0.50892037,\n",
       "        0.50596945, 0.49783501, 0.50819614, 0.51050663, 0.49619878,\n",
       "        0.51027317, 0.50785449, 0.49860609, 0.50826139, 0.50687928,\n",
       "        0.49937013, 0.50957787, 0.50804393, 0.49771745, 0.51124495,\n",
       "        0.50734084, 0.49565971, 0.51027284, 0.50914463, 0.49762019,\n",
       "        0.51236994, 0.5062449 , 0.50160524, 0.50937915, 0.50789101,\n",
       "        0.49352483, 0.50922603, 0.50936008, 0.4990676 , 0.50975136,\n",
       "        0.50561659, 0.49764792, 0.51215132, 0.50859197, 0.49915128,\n",
       "        0.50926721, 0.50717984, 0.4974408 , 0.51058143, 0.5075916 ,\n",
       "        0.49991515, 0.50951417, 0.5089561 , 0.4985331 , 0.50970172,\n",
       "        0.50732724, 0.49922059, 0.51083018, 0.50686825, 0.49558151,\n",
       "        0.50967619, 0.50539303, 0.49462476, 0.51056842, 0.50839999,\n",
       "        0.49960582, 0.51021567, 0.50783756, 0.50031911, 0.51125966,\n",
       "        0.50742892, 0.49730317, 0.51023007, 0.50670348, 0.49666745,\n",
       "        0.50897846, 0.50877748, 0.49617667, 0.5107054 , 0.50835063,\n",
       "        0.49759938]),\n",
       " 'split1_test_score': array([0.49484838, 0.49577944, 0.4818594 , 0.49451301, 0.49706214,\n",
       "        0.48645536, 0.49607346, 0.49767207, 0.48637737, 0.49874085,\n",
       "        0.49604804, 0.48853817, 0.49485637, 0.49535894, 0.48587486,\n",
       "        0.49610444, 0.49870257, 0.49087629, 0.4986953 , 0.49760203,\n",
       "        0.49025935, 0.49801594, 0.49674715, 0.48726597, 0.49541556,\n",
       "        0.49638575, 0.48512353, 0.49536435, 0.49746484, 0.48742807,\n",
       "        0.49438134, 0.49786271, 0.49229312, 0.49569479, 0.49899565,\n",
       "        0.48893222, 0.49625461, 0.49869651, 0.48490461, 0.49859122,\n",
       "        0.50056297, 0.48611433, 0.49902555, 0.4954617 , 0.48740128,\n",
       "        0.50116144, 0.50090358, 0.48619477, 0.49590275, 0.49797761,\n",
       "        0.48722322, 0.49728855, 0.49781567, 0.48780791, 0.49996077,\n",
       "        0.49528105, 0.48817359, 0.49735109, 0.49736981, 0.48822413,\n",
       "        0.49783699, 0.49642509, 0.48859431, 0.4964661 , 0.50087597,\n",
       "        0.48698948, 0.49690686, 0.49887659, 0.48964988, 0.49803462,\n",
       "        0.49748192, 0.49183234, 0.49782935, 0.49758763, 0.48701957,\n",
       "        0.49750709, 0.49889259, 0.49039872, 0.49661916, 0.49980797,\n",
       "        0.48932849]),\n",
       " 'mean_test_score': array([0.50260254, 0.4998118 , 0.48808255, 0.50202505, 0.50173776,\n",
       "        0.4912682 , 0.50284428, 0.50257028, 0.49122362, 0.50383061,\n",
       "        0.50100874, 0.49318659, 0.50152625, 0.50293279, 0.49103682,\n",
       "        0.50318881, 0.50327853, 0.49474119, 0.50347834, 0.50224065,\n",
       "        0.49481474, 0.5037969 , 0.50239554, 0.49249171, 0.50333025,\n",
       "        0.5018633 , 0.49039162, 0.50281859, 0.50330474, 0.49252413,\n",
       "        0.50337564, 0.50205381, 0.49694918, 0.50253697, 0.50344333,\n",
       "        0.49122853, 0.50274032, 0.50402829, 0.49198611, 0.50417129,\n",
       "        0.50308978, 0.49188113, 0.50558843, 0.50202684, 0.49327628,\n",
       "        0.50521432, 0.50404171, 0.49181778, 0.50324209, 0.5027846 ,\n",
       "        0.49356918, 0.50340136, 0.50338589, 0.49317051, 0.50483125,\n",
       "        0.50130414, 0.49369709, 0.50409063, 0.50211903, 0.49190282,\n",
       "        0.50375659, 0.50090906, 0.49160954, 0.50351726, 0.50463798,\n",
       "        0.49329765, 0.50356126, 0.50335708, 0.49498449, 0.50464714,\n",
       "        0.50245542, 0.49456776, 0.50402971, 0.50214556, 0.49184351,\n",
       "        0.50324278, 0.50383503, 0.49328769, 0.50366228, 0.5040793 ,\n",
       "        0.49346394]),\n",
       " 'std_test_score': array([0.00775416, 0.00403237, 0.00622316, 0.00751203, 0.00467563,\n",
       "        0.00481285, 0.00677082, 0.00489821, 0.00484625, 0.00508976,\n",
       "        0.0049607 , 0.00464842, 0.00666989, 0.00757385, 0.00516196,\n",
       "        0.00708436, 0.00457596, 0.0038649 , 0.00478305, 0.00463862,\n",
       "        0.00455539, 0.00578097, 0.00564839, 0.00522574, 0.0079147 ,\n",
       "        0.00547754, 0.00526809, 0.00745425, 0.0058399 , 0.00509606,\n",
       "        0.0089943 , 0.00419109, 0.00465606, 0.00684218, 0.00444768,\n",
       "        0.0022963 , 0.00648571, 0.00533179, 0.00708149, 0.00558007,\n",
       "        0.00252681, 0.00576679, 0.00656288, 0.00656514, 0.005875  ,\n",
       "        0.00405288, 0.00313813, 0.00562302, 0.00733934, 0.004807  ,\n",
       "        0.00634597, 0.00611281, 0.00557021, 0.0053626 , 0.00487047,\n",
       "        0.00602309, 0.0055235 , 0.00673955, 0.00474922, 0.00367869,\n",
       "        0.0059196 , 0.00448397, 0.00301522, 0.00705116, 0.00376201,\n",
       "        0.00630817, 0.0066544 , 0.00448049, 0.00533462, 0.00661252,\n",
       "        0.0049735 , 0.00273541, 0.00620036, 0.00455793, 0.00482394,\n",
       "        0.00573568, 0.00494244, 0.00288897, 0.00704312, 0.00427133,\n",
       "        0.00413545]),\n",
       " 'rank_test_score': array([37, 54, 81, 47, 49, 76, 33, 38, 78, 13, 52, 66, 50, 32, 79, 30, 27,\n",
       "        58, 19, 42, 57, 14, 41, 69, 25, 48, 80, 34, 26, 68, 23, 45, 55, 39,\n",
       "        20, 77, 36, 11, 70,  6, 31, 72,  1, 46, 65,  2,  9, 74, 29, 35, 61,\n",
       "        21, 22, 67,  3, 51, 60,  7, 44, 71, 15, 53, 75, 18,  5, 63, 17, 24,\n",
       "        56,  4, 40, 59, 10, 43, 73, 28, 12, 64, 16,  8, 62])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_countVectorizer__max_df: 0.75\n",
      "Best param_countVectorizer__max_features: 500\n",
      "Best param_MultiRandomForest__estimator__n_estimators 100\n",
      "Best param_MultiRandomForest__estimator__min_samples_split: 4\n"
     ]
    }
   ],
   "source": [
    "best_param_index = np.argmin(cv.cv_results_['rank_test_score'])\n",
    "print(f\"Best param_countVectorizer__max_df: {cv.cv_results_['param_countVectorizer__max_df'][best_param_index]}\")\n",
    "print(f\"Best param_countVectorizer__max_features: {cv.cv_results_['param_countVectorizer__max_features'][best_param_index]}\")\n",
    "print(f\"Best param_MultiRandomForest__estimator__n_estimators {cv.cv_results_['param_MultiRandomForest__estimator__n_estimators'][best_param_index]}\")\n",
    "print(f\"Best param_MultiRandomForest__estimator__min_samples_split: {cv.cv_results_['param_MultiRandomForest__estimator__min_samples_split'][best_param_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file ../../models\\MultiRandomForest_505588_20201201_104554.model\n"
     ]
    }
   ],
   "source": [
    "outpath = r\"../../models\"\n",
    "modeltype = list(cv.best_estimator_.named_steps)[-1]\n",
    "score   = f\"{int(cv.best_score_ * 1e6):06d}\"\n",
    "date    = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "outfilename = os.path.join(outpath, f\"{modeltype}_{score}_{date}.model\")\n",
    "with open(outfilename, 'wb') as outfile:\n",
    "    pickle.dump(cv, outfile)\n",
    "print(f\"Wrote file {outfilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('TFIDF', TfidfTransformer()),\n",
    "    ('ComplementNB', MultiOutputClassifier(ComplementNB(), n_jobs=14))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'countVectorizer__max_df': (0.25, 0.5, 0.75),\n",
    "        'countVectorizer__max_features': (500, 1000, 5000),\n",
    "        'ComplementNB__estimator__alpha': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "    }\n",
    "\n",
    "# Score by f1 score\n",
    "f1_weighted_score = make_scorer(f1_score, average='weighted', zero_division=0)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, scoring=f1_weighted_score, n_jobs=1, verbose=5, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 45 candidates, totalling 90 fits\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.445, total= 3.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.443, total= 3.5min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.452, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.453, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 14.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.430, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.426, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.445, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.443, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.452, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.453, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.430, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.426, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.445, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.443, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.452, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.453, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.430, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.426, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.444, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.443, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.452, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.454, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.462, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.465, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.444, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.443, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.452, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.454, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.462, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.465, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.444, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.443, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.452, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.454, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.462, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.25, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.465, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.443, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.442, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.448, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.450, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.457, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.460, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.443, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.442, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.448, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.450, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.457, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.460, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.443, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.442, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.448, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.450, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.457, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.5, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.460, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.441, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.441, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.444, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.447, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.455, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.458, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.441, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.441, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.444, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.447, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.455, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.458, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.441, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.441, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.444, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.447, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.455, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=0.75, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.458, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.440, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=500, score=0.439, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.442, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=1000, score=0.444, total= 4.0min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.451, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.25, countVectorizer__max_features=5000, score=0.454, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.440, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=500, score=0.439, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.442, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=1000, score=0.444, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.451, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.5, countVectorizer__max_features=5000, score=0.454, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.440, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=500 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=500, score=0.439, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.442, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=1000, score=0.444, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.451, total= 3.9min\n",
      "[CV] ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000 \n",
      "[CV]  ComplementNB__estimator__alpha=1.0, countVectorizer__max_df=0.75, countVectorizer__max_features=5000, score=0.454, total= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 353.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5h 57min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('countVectorizer',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x000002288BF6D430>)),\n",
       "                                       ('TFIDF', TfidfTransformer()),\n",
       "                                       ('ComplementNB',\n",
       "                                        MultiOutputClassifier(estimator=ComplementNB(),\n",
       "                                                              n_jobs=14))]),\n",
       "             n_jobs=1,\n",
       "             param_grid={'ComplementNB__estimator__alpha': [0, 0.25, 0.5, 0.75,\n",
       "                                                            1.0],\n",
       "                         'countVectorizer__max_df': (0.25, 0.5, 0.75),\n",
       "                         'countVectorizer__max_features': (500, 1000, 5000)},\n",
       "             scoring=make_scorer(f1_score, average=weighted, zero_division=0),\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 89.50700867, 119.4877404 , 119.87895346, 119.52050042,\n",
       "        118.75770736, 118.65534925, 119.46136558, 118.96802056,\n",
       "        119.46336019, 118.88865781, 119.23923147, 120.29551971,\n",
       "        118.61435914, 118.68232822, 118.1525141 , 118.50276959,\n",
       "        118.09186554, 118.25676048, 118.68215907, 118.01186311,\n",
       "        118.18677056, 118.27757692, 118.1262157 , 118.38759995,\n",
       "        118.15856576, 118.23968649, 118.82146788, 119.10368431,\n",
       "        119.01632524, 118.41697466, 119.04488897, 117.86802018,\n",
       "        118.92249215, 119.2589761 , 118.3115592 , 119.42037272,\n",
       "        118.14375448, 118.65193927, 117.43929482, 117.16972113,\n",
       "        117.29077709, 117.23652637, 116.55385864, 116.42628074,\n",
       "        116.65570962]),\n",
       " 'std_fit_time': array([1.0734762 , 0.88614357, 0.66457677, 0.17054272, 0.67632866,\n",
       "        0.84413433, 0.01173007, 0.57982624, 1.25282013, 0.99604416,\n",
       "        0.19750845, 1.06358087, 0.64857841, 1.47726297, 0.58128679,\n",
       "        0.30657661, 0.44742846, 0.91737139, 0.64402711, 1.07274759,\n",
       "        0.25948107, 0.77102637, 0.37653112, 0.9882617 , 0.93371344,\n",
       "        0.52829742, 0.25778604, 0.21697319, 1.12164688, 0.39355099,\n",
       "        1.21221757, 0.81507456, 0.4444133 , 1.19531   , 0.19366241,\n",
       "        1.18311024, 0.29338717, 0.30757153, 1.08772302, 0.62252188,\n",
       "        0.83741558, 0.89257491, 0.57416999, 0.50700545, 0.5515362 ]),\n",
       " 'mean_score_time': array([103.79653978, 118.92756546, 118.94298434, 119.15872884,\n",
       "        118.56318128, 118.96069646, 118.80414867, 119.7584995 ,\n",
       "        118.62920296, 118.82106864, 118.56806827, 118.9301759 ,\n",
       "        119.13499784, 117.98822761, 118.82189322, 118.03490126,\n",
       "        117.93189943, 118.72355652, 117.59158552, 118.14304519,\n",
       "        118.42105961, 118.23860049, 117.43992746, 118.77431369,\n",
       "        118.33915651, 117.85091794, 120.23044753, 118.75410938,\n",
       "        118.21562195, 118.07580447, 117.93160284, 118.64356136,\n",
       "        118.04481316, 118.76357591, 118.1677953 , 118.35469449,\n",
       "        118.50795698, 118.32542682, 119.09211695, 117.45640743,\n",
       "        116.60222137, 116.51465964, 116.95139921, 116.52741921,\n",
       "        117.18252873]),\n",
       " 'std_score_time': array([15.61605358,  0.51300156,  0.21382642,  0.62059879,  0.7311393 ,\n",
       "         0.17474174,  0.26412368,  1.60579574,  0.61152971,  1.25650179,\n",
       "         0.27218771,  0.98591077,  0.35073113,  0.46473527,  0.04397035,\n",
       "         0.8314203 ,  0.75575411,  0.46654844,  0.77072132,  0.7952683 ,\n",
       "         0.05318713,  0.40911055,  0.26260316,  0.61963725,  0.35580337,\n",
       "         0.93707693,  1.46092105,  0.25150585,  0.20256782,  0.37099195,\n",
       "         0.79559076,  0.46575785,  0.66383862,  0.28289378,  0.08134496,\n",
       "         1.10612953,  0.61124444,  0.47638011,  0.74428546,  0.38069594,\n",
       "         0.62770498,  0.28436565,  0.46060002,  0.49449074,  0.23890471]),\n",
       " 'param_ComplementNB__estimator__alpha': masked_array(data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25, 0.25, 0.25, 0.25,\n",
       "                    0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "                    0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_countVectorizer__max_df': masked_array(data=[0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_countVectorizer__max_features': masked_array(data=[500, 1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000, 500,\n",
       "                    1000, 5000, 500, 1000, 5000, 500, 1000, 5000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.25,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.5,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 0.75,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.25,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.5,\n",
       "   'countVectorizer__max_features': 5000},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 500},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 1000},\n",
       "  {'ComplementNB__estimator__alpha': 1.0,\n",
       "   'countVectorizer__max_df': 0.75,\n",
       "   'countVectorizer__max_features': 5000}],\n",
       " 'split0_test_score': array([0.44510641, 0.45163996, 0.43036851, 0.44510641, 0.45163996,\n",
       "        0.43036851, 0.44510641, 0.45163996, 0.43036851, 0.44431595,\n",
       "        0.4516888 , 0.46170351, 0.44431595, 0.4516888 , 0.46170351,\n",
       "        0.44431595, 0.4516888 , 0.46170351, 0.44263376, 0.44775493,\n",
       "        0.45749958, 0.44263376, 0.44775493, 0.45749958, 0.44263376,\n",
       "        0.44775493, 0.45749958, 0.44094333, 0.44436686, 0.45515665,\n",
       "        0.44094333, 0.44436686, 0.45515665, 0.44094333, 0.44436686,\n",
       "        0.45515665, 0.43962872, 0.44194127, 0.45146226, 0.43962872,\n",
       "        0.44194127, 0.45146226, 0.43962872, 0.44194127, 0.45146226]),\n",
       " 'split1_test_score': array([0.44290284, 0.45287057, 0.42626163, 0.44290284, 0.45287057,\n",
       "        0.42626163, 0.44290284, 0.45287057, 0.42626163, 0.44343027,\n",
       "        0.45356056, 0.46450916, 0.44343027, 0.45356056, 0.46450916,\n",
       "        0.44343027, 0.45356056, 0.46450916, 0.44205313, 0.44972161,\n",
       "        0.46015606, 0.44205313, 0.44972161, 0.46015606, 0.44205313,\n",
       "        0.44972161, 0.46015606, 0.44064528, 0.44661261, 0.45761965,\n",
       "        0.44064528, 0.44661261, 0.45761965, 0.44064528, 0.44661261,\n",
       "        0.45761965, 0.43889072, 0.44372726, 0.45392896, 0.43889072,\n",
       "        0.44372726, 0.45392896, 0.43889072, 0.44372726, 0.45392896]),\n",
       " 'mean_test_score': array([0.44400462, 0.45225526, 0.42831507, 0.44400462, 0.45225526,\n",
       "        0.42831507, 0.44400462, 0.45225526, 0.42831507, 0.44387311,\n",
       "        0.45262468, 0.46310634, 0.44387311, 0.45262468, 0.46310634,\n",
       "        0.44387311, 0.45262468, 0.46310634, 0.44234344, 0.44873827,\n",
       "        0.45882782, 0.44234344, 0.44873827, 0.45882782, 0.44234344,\n",
       "        0.44873827, 0.45882782, 0.4407943 , 0.44548974, 0.45638815,\n",
       "        0.4407943 , 0.44548974, 0.45638815, 0.4407943 , 0.44548974,\n",
       "        0.45638815, 0.43925972, 0.44283427, 0.45269561, 0.43925972,\n",
       "        0.44283427, 0.45269561, 0.43925972, 0.44283427, 0.45269561]),\n",
       " 'std_test_score': array([0.00110179, 0.00061531, 0.00205344, 0.00110179, 0.00061531,\n",
       "        0.00205344, 0.00110179, 0.00061531, 0.00205344, 0.00044284,\n",
       "        0.00093588, 0.00140283, 0.00044284, 0.00093588, 0.00140283,\n",
       "        0.00044284, 0.00093588, 0.00140283, 0.00029031, 0.00098334,\n",
       "        0.00132824, 0.00029031, 0.00098334, 0.00132824, 0.00029031,\n",
       "        0.00098334, 0.00132824, 0.00014902, 0.00112287, 0.0012315 ,\n",
       "        0.00014902, 0.00112287, 0.0012315 , 0.00014902, 0.00112287,\n",
       "        0.0012315 , 0.000369  , 0.00089299, 0.00123335, 0.000369  ,\n",
       "        0.00089299, 0.00123335, 0.000369  , 0.00089299, 0.00123335]),\n",
       " 'rank_test_score': array([25, 16, 43, 25, 16, 43, 25, 16, 43, 28, 13,  1, 28, 13,  1, 28, 13,\n",
       "         1, 34, 19,  4, 34, 19,  4, 34, 19,  4, 37, 22,  7, 37, 22,  7, 37,\n",
       "        22,  7, 40, 31, 10, 40, 31, 10, 40, 31, 10])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_countVectorizer__max_df: 0.25\n",
      "Best param_countVectorizer__max_features: 5000\n",
      "Best param_ComplementNB__estimator__alpha: 0.25\n"
     ]
    }
   ],
   "source": [
    "best_param_index = np.argmin(cv.cv_results_['rank_test_score'])\n",
    "print(f\"Best param_countVectorizer__max_df: {cv.cv_results_['param_countVectorizer__max_df'][best_param_index]}\")\n",
    "print(f\"Best param_countVectorizer__max_features: {cv.cv_results_['param_countVectorizer__max_features'][best_param_index]}\")\n",
    "print(f\"Best param_ComplementNB__estimator__alpha: {cv.cv_results_['param_ComplementNB__estimator__alpha'][best_param_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file ../../models\\ComplementNB_463106_20201128_041450.model\n"
     ]
    }
   ],
   "source": [
    "outpath = r\"../../models\"\n",
    "modeltype = list(cv.best_estimator_.named_steps)[-1]\n",
    "score   = f\"{int(cv.best_score_ * 1e6):06d}\"\n",
    "date    = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "outfilename = os.path.join(outpath, f\"{modeltype}_{score}_{date}.model\")\n",
    "with open(outfilename, 'wb') as outfile:\n",
    "    pickle.dump(cv, outfile)\n",
    "print(f\"Wrote file {outfilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model accuracy: {accuracy_score(Y_test, Y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.82      0.50      0.62      1073\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.76      0.68      0.72      2658\n",
      "          medical_help       0.64      0.09      0.16       505\n",
      "      medical_products       0.81      0.08      0.15       308\n",
      "     search_and_rescue       0.86      0.04      0.07       166\n",
      "              security       1.00      0.01      0.01       136\n",
      "              military       0.73      0.05      0.09       234\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.88      0.36      0.51       413\n",
      "                  food       0.83      0.55      0.66       712\n",
      "               shelter       0.81      0.41      0.54       581\n",
      "              clothing       1.00      0.06      0.11       102\n",
      "                 money       1.00      0.03      0.06       152\n",
      "        missing_people       0.00      0.00      0.00        79\n",
      "              refugees       0.80      0.02      0.04       205\n",
      "                 death       0.83      0.19      0.30       279\n",
      "             other_aid       0.61      0.03      0.06       834\n",
      "infrastructure_related       0.00      0.00      0.00       421\n",
      "             transport       0.79      0.09      0.15       305\n",
      "             buildings       0.78      0.09      0.16       343\n",
      "           electricity       0.62      0.04      0.07       141\n",
      "                 tools       0.00      0.00      0.00        48\n",
      "             hospitals       0.00      0.00      0.00        57\n",
      "                 shops       0.00      0.00      0.00        29\n",
      "           aid_centers       0.00      0.00      0.00        77\n",
      "  other_infrastructure       0.00      0.00      0.00       295\n",
      "       weather_related       0.85      0.71      0.77      1835\n",
      "                floods       0.90      0.45      0.60       529\n",
      "                 storm       0.78      0.55      0.64       644\n",
      "                  fire       1.00      0.01      0.03        73\n",
      "            earthquake       0.91      0.81      0.86       598\n",
      "                  cold       0.68      0.10      0.18       125\n",
      "         other_weather       0.38      0.02      0.04       342\n",
      "         direct_report       0.79      0.36      0.50      1264\n",
      "\n",
      "             micro avg       0.81      0.40      0.54     15589\n",
      "             macro avg       0.60      0.18      0.23     15589\n",
      "          weighted avg       0.74      0.40      0.47     15589\n",
      "           samples avg       0.41      0.24      0.28     15589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Y_test, Y_pred, target_names=Y_test.columns, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction probabilities for individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs and requirements: metal caskets/coffins, medical supplies, medicines, rubber gloves, masks, tents and office supplies, blankets, clothes, heavy equipment, power generators, water purifiers, forensic pathologists, freezer containers for bodies, communications equipment, dried or canned food and rice.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_c34a222a_30f3_11eb_8bab_005056aa725crow0_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow1_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow2_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow3_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow4_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow5_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow6_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow7_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow8_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow9_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow10_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow11_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow12_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow13_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow14_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow15_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow16_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow17_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow18_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow19_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow20_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow21_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow22_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow23_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow24_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow25_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow26_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow27_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow28_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow29_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow30_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow31_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow32_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow33_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow34_col2{\n",
       "            color:  green;\n",
       "        }#T_c34a222a_30f3_11eb_8bab_005056aa725crow0_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow1_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow2_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow3_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow4_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow5_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow6_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow7_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow8_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow9_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow10_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow11_col2,#T_c34a222a_30f3_11eb_8bab_005056aa725crow12_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow13_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow14_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow15_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow16_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow17_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow18_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow19_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow20_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow21_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow22_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow23_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow24_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow25_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow26_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow27_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow28_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow29_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow30_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow31_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow32_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow33_col3,#T_c34a222a_30f3_11eb_8bab_005056aa725crow34_col3{\n",
       "            color:  red;\n",
       "        }</style><table id=\"T_c34a222a_30f3_11eb_8bab_005056aa725c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >prediction</th>        <th class=\"col_heading level0 col1\" >truth</th>        <th class=\"col_heading level0 col2\" >proba_0</th>        <th class=\"col_heading level0 col3\" >proba_1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row0\" class=\"row_heading level0 row0\" >request</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow0_col1\" class=\"data row0 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow0_col2\" class=\"data row0 col2\" >0.800000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow0_col3\" class=\"data row0 col3\" >0.200000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row1\" class=\"row_heading level0 row1\" >offer</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row2\" class=\"row_heading level0 row2\" >aid_related</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow2_col0\" class=\"data row2 col0\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow2_col1\" class=\"data row2 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow2_col2\" class=\"data row2 col2\" >0.090000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow2_col3\" class=\"data row2 col3\" >0.910000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row3\" class=\"row_heading level0 row3\" >medical_help</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow3_col1\" class=\"data row3 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow3_col2\" class=\"data row3 col2\" >0.810000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow3_col3\" class=\"data row3 col3\" >0.190000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row4\" class=\"row_heading level0 row4\" >medical_products</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow4_col1\" class=\"data row4 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow4_col2\" class=\"data row4 col2\" >0.610000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow4_col3\" class=\"data row4 col3\" >0.390000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row5\" class=\"row_heading level0 row5\" >search_and_rescue</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow5_col2\" class=\"data row5 col2\" >0.990000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow5_col3\" class=\"data row5 col3\" >0.010000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row6\" class=\"row_heading level0 row6\" >security</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow6_col0\" class=\"data row6 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow6_col1\" class=\"data row6 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow6_col2\" class=\"data row6 col2\" >0.970000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow6_col3\" class=\"data row6 col3\" >0.030000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row7\" class=\"row_heading level0 row7\" >military</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow7_col0\" class=\"data row7 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow7_col1\" class=\"data row7 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow7_col2\" class=\"data row7 col2\" >0.990000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow7_col3\" class=\"data row7 col3\" >0.010000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row8\" class=\"row_heading level0 row8\" >child_alone</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow8_col0\" class=\"data row8 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow8_col1\" class=\"data row8 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow8_col2\" class=\"data row8 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row9\" class=\"row_heading level0 row9\" >water</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow9_col0\" class=\"data row9 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow9_col1\" class=\"data row9 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow9_col2\" class=\"data row9 col2\" >0.610000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow9_col3\" class=\"data row9 col3\" >0.390000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row10\" class=\"row_heading level0 row10\" >food</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow10_col0\" class=\"data row10 col0\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow10_col1\" class=\"data row10 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow10_col2\" class=\"data row10 col2\" >0.470000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow10_col3\" class=\"data row10 col3\" >0.530000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row11\" class=\"row_heading level0 row11\" >shelter</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow11_col0\" class=\"data row11 col0\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow11_col1\" class=\"data row11 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow11_col2\" class=\"data row11 col2\" >0.410000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow11_col3\" class=\"data row11 col3\" >0.590000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row12\" class=\"row_heading level0 row12\" >clothing</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow12_col0\" class=\"data row12 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow12_col1\" class=\"data row12 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow12_col2\" class=\"data row12 col2\" >0.920000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow12_col3\" class=\"data row12 col3\" >0.080000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row13\" class=\"row_heading level0 row13\" >money</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow13_col0\" class=\"data row13 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow13_col1\" class=\"data row13 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow13_col2\" class=\"data row13 col2\" >0.990000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow13_col3\" class=\"data row13 col3\" >0.010000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row14\" class=\"row_heading level0 row14\" >missing_people</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow14_col0\" class=\"data row14 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow14_col1\" class=\"data row14 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow14_col2\" class=\"data row14 col2\" >0.990000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow14_col3\" class=\"data row14 col3\" >0.010000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row15\" class=\"row_heading level0 row15\" >refugees</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow15_col0\" class=\"data row15 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow15_col1\" class=\"data row15 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow15_col2\" class=\"data row15 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow15_col3\" class=\"data row15 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row16\" class=\"row_heading level0 row16\" >death</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow16_col0\" class=\"data row16 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow16_col1\" class=\"data row16 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow16_col2\" class=\"data row16 col2\" >0.880000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow16_col3\" class=\"data row16 col3\" >0.120000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row17\" class=\"row_heading level0 row17\" >other_aid</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow17_col0\" class=\"data row17 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow17_col1\" class=\"data row17 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow17_col2\" class=\"data row17 col2\" >0.800000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow17_col3\" class=\"data row17 col3\" >0.200000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row18\" class=\"row_heading level0 row18\" >infrastructure_related</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow18_col0\" class=\"data row18 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow18_col1\" class=\"data row18 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow18_col2\" class=\"data row18 col2\" >0.970000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow18_col3\" class=\"data row18 col3\" >0.030000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row19\" class=\"row_heading level0 row19\" >transport</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow19_col0\" class=\"data row19 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow19_col1\" class=\"data row19 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow19_col2\" class=\"data row19 col2\" >0.940000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow19_col3\" class=\"data row19 col3\" >0.060000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row20\" class=\"row_heading level0 row20\" >buildings</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow20_col0\" class=\"data row20 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow20_col1\" class=\"data row20 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow20_col2\" class=\"data row20 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow20_col3\" class=\"data row20 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row21\" class=\"row_heading level0 row21\" >electricity</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow21_col0\" class=\"data row21 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow21_col1\" class=\"data row21 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow21_col2\" class=\"data row21 col2\" >0.860000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow21_col3\" class=\"data row21 col3\" >0.140000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row22\" class=\"row_heading level0 row22\" >tools</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow22_col0\" class=\"data row22 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow22_col1\" class=\"data row22 col1\" >1</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow22_col2\" class=\"data row22 col2\" >0.950000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow22_col3\" class=\"data row22 col3\" >0.050000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row23\" class=\"row_heading level0 row23\" >hospitals</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow23_col0\" class=\"data row23 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow23_col1\" class=\"data row23 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow23_col2\" class=\"data row23 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow23_col3\" class=\"data row23 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row24\" class=\"row_heading level0 row24\" >shops</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow24_col0\" class=\"data row24 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow24_col1\" class=\"data row24 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow24_col2\" class=\"data row24 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow24_col3\" class=\"data row24 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row25\" class=\"row_heading level0 row25\" >aid_centers</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow25_col0\" class=\"data row25 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow25_col1\" class=\"data row25 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow25_col2\" class=\"data row25 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow25_col3\" class=\"data row25 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row26\" class=\"row_heading level0 row26\" >other_infrastructure</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow26_col0\" class=\"data row26 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow26_col1\" class=\"data row26 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow26_col2\" class=\"data row26 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow26_col3\" class=\"data row26 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row27\" class=\"row_heading level0 row27\" >weather_related</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow27_col0\" class=\"data row27 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow27_col1\" class=\"data row27 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow27_col2\" class=\"data row27 col2\" >0.680000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow27_col3\" class=\"data row27 col3\" >0.320000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row28\" class=\"row_heading level0 row28\" >floods</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow28_col0\" class=\"data row28 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow28_col1\" class=\"data row28 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow28_col2\" class=\"data row28 col2\" >0.900000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow28_col3\" class=\"data row28 col3\" >0.100000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row29\" class=\"row_heading level0 row29\" >storm</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow29_col0\" class=\"data row29 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow29_col1\" class=\"data row29 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow29_col2\" class=\"data row29 col2\" >0.940000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow29_col3\" class=\"data row29 col3\" >0.060000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row30\" class=\"row_heading level0 row30\" >fire</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow30_col0\" class=\"data row30 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow30_col1\" class=\"data row30 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow30_col2\" class=\"data row30 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow30_col3\" class=\"data row30 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row31\" class=\"row_heading level0 row31\" >earthquake</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow31_col0\" class=\"data row31 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow31_col1\" class=\"data row31 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow31_col2\" class=\"data row31 col2\" >0.990000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow31_col3\" class=\"data row31 col3\" >0.010000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row32\" class=\"row_heading level0 row32\" >cold</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow32_col0\" class=\"data row32 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow32_col1\" class=\"data row32 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow32_col2\" class=\"data row32 col2\" >0.980000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow32_col3\" class=\"data row32 col3\" >0.020000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row33\" class=\"row_heading level0 row33\" >other_weather</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow33_col0\" class=\"data row33 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow33_col1\" class=\"data row33 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow33_col2\" class=\"data row33 col2\" >0.970000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow33_col3\" class=\"data row33 col3\" >0.030000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c34a222a_30f3_11eb_8bab_005056aa725clevel0_row34\" class=\"row_heading level0 row34\" >direct_report</th>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow34_col0\" class=\"data row34 col0\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow34_col1\" class=\"data row34 col1\" >0</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow34_col2\" class=\"data row34 col2\" >0.830000</td>\n",
       "                        <td id=\"T_c34a222a_30f3_11eb_8bab_005056aa725crow34_col3\" class=\"data row34 col3\" >0.170000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22893cc7df0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 3\n",
    "Y_pred = pd.DataFrame(Y_pred, columns=Y_test.columns, index=X_test.index)\n",
    "pp = clf.predict_proba(X_test_tfidf[sample])\n",
    "pred_proba = pd.DataFrame(Y_pred.iloc[sample])\n",
    "pred_proba.columns  = [\"prediction\"]\n",
    "pred_proba[\"truth\"] = Y_test.iloc[sample]\n",
    "pred_proba[\"proba_0\"] = [a[0][0] for a in pp]\n",
    "pred_proba[\"proba_1\"] = [a[0][1] if len(a[0])>1 else 0.0 for a in pp]\n",
    "print(X_test.iloc[sample])\n",
    "pred_proba.style.applymap(lambda v: 'color: red' if v < 0.5 else 'color: green', subset=[\"proba_0\", \"proba_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    " * Naive Bayes (Multinomial, Complement)\n",
    " * Nearest Neighbours (KNeighborsClassifier)\n",
    "\n",
    "Model         | precision  |  recall | f1-score | Further parameters\n",
    "--------------|------------|---------|----------|------------------------------\n",
    "RandomForest  |      0.70  |    0.45 |     0.51 | max_df=0.5, max_features=1000\n",
    "ComplementNB  |      0.47  |    0.36 |     0.39 | defaults\n",
    "ComplementNB  |      0.36  |    0.77 |     0.46 | max_df=0.5, max_features=1000\n",
    "MultinomialNB |      0.70  |    0.32 |     0.39 | max_df=0.5, max_features=1000\n",
    "KNeighbors    |      0.62  |    0.12 |     0.20 | max_df=0.5, max_features=1000\n",
    "KNeighbors    |            |         |     0.11 | n_neighbors=10\n",
    "KNeighbors    |            |         |     0.08 | n_neighbors=20\n",
    "KNeighbors    |            |         |     0.03 | n_neighbors=50\n",
    "KNeighbors    |            |         |     0.01 | n_neighbors=100\n",
    "\n",
    "**Conclusion:**\n",
    "Use Random Forest for best f1-score and best precision, but ComplementNB for best recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer(tokenizer=tokenize, max_df=0.5, max_features=1000)),\n",
    "    ('TFIDF', TfidfTransformer()),\n",
    "    ('classifier', MultiOutputClassifier(SVC()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Y_pred, target_names=Y_test.columns, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'classifier__estimator__n_neighbors': [10, 20, 50, 100],\n",
    "    }\n",
    "\n",
    "# Score by f1 score\n",
    "f1_weighted_score = make_scorer(f1_score, average='weighted', zero_division=0)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, scoring=f1_weighted_score, n_jobs=1, verbose=1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file\n",
    "With the results from above, the best performing models are (now trained with the full dataset):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest\n",
    "**highest f1-score** (0.51), **highest precision (0.71)**, sufficient recall (0.44), sufficient accuracy (0.41) [weighted averages]\n",
    "* Random Forest with \n",
    "    * CountVectorizer max_df=0.25\n",
    "    * CountVectorizer max_features=5000\n",
    "    * RandomForest n_estimators=100\n",
    "    * RandomForest min_samples_split=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_pipeline = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer(tokenizer=tokenize, max_df=0.25, max_features=5000)),\n",
    "    ('TFIDF', TfidfTransformer()),\n",
    "    ('MultiRandomForest', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, min_samples_split=4), n_jobs=14))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countVectorizer',\n",
       "                 CountVectorizer(max_df=0.25, max_features=5000,\n",
       "                                 tokenizer=<function tokenize at 0x000002288BF6D430>)),\n",
       "                ('TFIDF', TfidfTransformer()),\n",
       "                ('MultiRandomForest',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=4),\n",
       "                                       n_jobs=14))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time RandomForest_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.41\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.81      0.51      0.63      1073\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.73      0.71      0.72      2658\n",
      "          medical_help       0.56      0.13      0.21       505\n",
      "      medical_products       0.82      0.17      0.28       308\n",
      "     search_and_rescue       0.59      0.10      0.17       166\n",
      "              security       0.00      0.00      0.00       136\n",
      "              military       0.74      0.12      0.21       234\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.86      0.49      0.62       413\n",
      "                  food       0.82      0.70      0.76       712\n",
      "               shelter       0.80      0.50      0.61       581\n",
      "              clothing       0.82      0.18      0.29       102\n",
      "                 money       0.80      0.03      0.05       152\n",
      "        missing_people       0.33      0.01      0.02        79\n",
      "              refugees       0.56      0.07      0.12       205\n",
      "                 death       0.76      0.32      0.45       279\n",
      "             other_aid       0.49      0.05      0.09       834\n",
      "infrastructure_related       0.17      0.00      0.00       421\n",
      "             transport       0.74      0.12      0.21       305\n",
      "             buildings       0.76      0.13      0.22       343\n",
      "           electricity       0.72      0.09      0.16       141\n",
      "                 tools       0.00      0.00      0.00        48\n",
      "             hospitals       0.00      0.00      0.00        57\n",
      "                 shops       0.00      0.00      0.00        29\n",
      "           aid_centers       0.00      0.00      0.00        77\n",
      "  other_infrastructure       0.00      0.00      0.00       295\n",
      "       weather_related       0.84      0.75      0.79      1835\n",
      "                floods       0.89      0.55      0.68       529\n",
      "                 storm       0.74      0.65      0.69       644\n",
      "                  fire       1.00      0.04      0.08        73\n",
      "            earthquake       0.90      0.82      0.86       598\n",
      "                  cold       0.69      0.18      0.28       125\n",
      "         other_weather       0.54      0.08      0.14       342\n",
      "         direct_report       0.78      0.36      0.49      1264\n",
      "\n",
      "             micro avg       0.78      0.44      0.57     15589\n",
      "             macro avg       0.55      0.22      0.28     15589\n",
      "          weighted avg       0.71      0.44      0.51     15589\n",
      "           samples avg       0.42      0.27      0.31     15589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = RandomForest_pipeline.predict(X_test)\n",
    "print(f\"Model accuracy: {accuracy_score(Y_test, Y_pred):.2f}\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=Y_test.columns, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit with complete Dataset and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countVectorizer',\n",
       "                 CountVectorizer(max_df=0.25, max_features=5000,\n",
       "                                 tokenizer=<function tokenize at 0x000002288BF6D430>)),\n",
       "                ('TFIDF', TfidfTransformer()),\n",
       "                ('MultiRandomForest',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(min_samples_split=4),\n",
       "                                       n_jobs=14))])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time RandomForest_pipeline.fit(X[\"message\"], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file ../../models\\RandomForest.model\n"
     ]
    }
   ],
   "source": [
    "outpath = r\"../../models\"\n",
    "outfilename = os.path.join(outpath, f\"RandomForest.model\")\n",
    "with open(outfilename, 'wb') as outfile:\n",
    "    pickle.dump(RandomForest_pipeline, outfile)\n",
    "print(f\"Wrote file {outfilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes\n",
    "**good f1-score** (0.46), sufficient precision (0.36), **highest recall** (0.77), sufficient accuracy (0.08) [weighted averages]\n",
    "* Complement Naive Bayes with\n",
    "    * CountVectorizer max_df=0.25\n",
    "    * CountVectorizer max_features=5000\n",
    "    * ComplementNB alpha=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComplementNB_pipeline = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer(tokenizer=tokenize, max_df=0.25, max_features=5000)),\n",
    "    ('TFIDF', TfidfTransformer()),\n",
    "    ('ComplementNB', MultiOutputClassifier(ComplementNB(alpha=0.25), n_jobs=14))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countVectorizer',\n",
       "                 CountVectorizer(max_df=0.25, max_features=5000,\n",
       "                                 tokenizer=<function tokenize at 0x000002288BF6D430>)),\n",
       "                ('TFIDF', TfidfTransformer()),\n",
       "                ('ComplementNB',\n",
       "                 MultiOutputClassifier(estimator=ComplementNB(alpha=0.25),\n",
       "                                       n_jobs=14))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ComplementNB_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.08\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.46      0.82      0.59      1073\n",
      "                 offer       0.01      0.35      0.02        26\n",
      "           aid_related       0.65      0.75      0.70      2658\n",
      "          medical_help       0.22      0.67      0.33       505\n",
      "      medical_products       0.17      0.75      0.28       308\n",
      "     search_and_rescue       0.07      0.50      0.12       166\n",
      "              security       0.05      0.41      0.09       136\n",
      "              military       0.17      0.80      0.28       234\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.23      0.83      0.36       413\n",
      "                  food       0.36      0.82      0.50       712\n",
      "               shelter       0.28      0.81      0.42       581\n",
      "              clothing       0.10      0.74      0.18       102\n",
      "                 money       0.10      0.66      0.17       152\n",
      "        missing_people       0.03      0.44      0.06        79\n",
      "              refugees       0.08      0.68      0.15       205\n",
      "                 death       0.15      0.77      0.25       279\n",
      "             other_aid       0.24      0.60      0.34       834\n",
      "infrastructure_related       0.14      0.68      0.23       421\n",
      "             transport       0.12      0.62      0.19       305\n",
      "             buildings       0.17      0.74      0.28       343\n",
      "           electricity       0.08      0.69      0.14       141\n",
      "                 tools       0.01      0.27      0.03        48\n",
      "             hospitals       0.02      0.42      0.04        57\n",
      "                 shops       0.01      0.24      0.02        29\n",
      "           aid_centers       0.02      0.40      0.05        77\n",
      "  other_infrastructure       0.11      0.67      0.19       295\n",
      "       weather_related       0.61      0.77      0.68      1835\n",
      "                floods       0.23      0.79      0.36       529\n",
      "                 storm       0.37      0.86      0.52       644\n",
      "                  fire       0.04      0.56      0.07        73\n",
      "            earthquake       0.41      0.82      0.55       598\n",
      "                  cold       0.07      0.70      0.13       125\n",
      "         other_weather       0.13      0.65      0.22       342\n",
      "         direct_report       0.43      0.78      0.56      1264\n",
      "\n",
      "             micro avg       0.23      0.74      0.35     15589\n",
      "             macro avg       0.18      0.63      0.26     15589\n",
      "          weighted avg       0.37      0.74      0.47     15589\n",
      "           samples avg       0.25      0.44      0.28     15589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = ComplementNB_pipeline.predict(X_test)\n",
    "print(f\"Model accuracy: {accuracy_score(Y_test, Y_pred):.2f}\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=Y_test.columns, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit with complete Dataset and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countVectorizer',\n",
       "                 CountVectorizer(max_df=0.25, max_features=5000,\n",
       "                                 tokenizer=<function tokenize at 0x000002288BF6D430>)),\n",
       "                ('TFIDF', TfidfTransformer()),\n",
       "                ('ComplementNB',\n",
       "                 MultiOutputClassifier(estimator=ComplementNB(alpha=0.25),\n",
       "                                       n_jobs=14))])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ComplementNB_pipeline.fit(X[\"message\"], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file ../../models\\ComplementNB.model\n"
     ]
    }
   ],
   "source": [
    "outpath = r\"../../models\"\n",
    "outfilename = os.path.join(outpath, f\"ComplementNB.model\")\n",
    "with open(outfilename, 'wb') as outfile:\n",
    "    pickle.dump(ComplementNB_pipeline, outfile)\n",
    "print(f\"Wrote file {outfilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
